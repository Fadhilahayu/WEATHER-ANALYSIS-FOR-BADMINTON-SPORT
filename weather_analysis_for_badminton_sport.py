
# -*- coding: utf-8 -*-
\"\"\"WEATHER ANALYSIS FOR BADMINTON SPORT

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/fadhilahayumaharani/weather-analysis-for-badminton-sport.c5789e6e-d5b8-43cb-a30b-d5d970785c07.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20250614/auto/storage/goog4_request%26X-Goog-Date%3D20250614T100821Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D1bd4fb768c859a5079eefca79e052baf88b52b66875101883fc6805e09d1a453f8bb38fb408329173706788b214d6f3c2ac5cadc0c3f4aa1464778a1e17ee51bda4965499edcf7c7b494db9896874e1213b051c2bb93600fdc58a24e1195d16d4d826f3a370d5747a107e784c537ffec052023964f0feff69528a874d3cdec0991f39e4f4495603c19bbb333722ba68495f309312357306293cb260b3304ccfa3e27ebb771e45cef3601f2dfffb08b9358437f0670478b3ee30033508bf09947423beb31214198fbe24aa6e51529924035fa9e1f52919681bbe96222e67066daac8596f84c85e66ff51930833508a9aa98140eea5d38eebadaa30bf51fbbdfaf
\"\"\"

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.
import kagglehub
# CORRECTION 1: Import the 'os' module to help construct file paths
import os
smid80_weatherww2_path = kagglehub.dataset_download('smid80/weatherww2')
muthuj7_weather_dataset_path = kagglehub.dataset_download('muthuj7/weather-dataset')
canggih_badminton_game_data_bwf_super_series_20152017_path = kagglehub.dataset_download('canggih/badminton-game-data-bwf-super-series-20152017')
vijaygiitk_multiclass_weather_dataset_path = kagglehub.dataset_download('vijaygiitk/multiclass-weather-dataset')
ananthr1_weather_prediction_path = kagglehub.dataset_download('ananthr1/weather-prediction')
emmanuelfwerr_london_weather_data_path = kagglehub.dataset_download('emmanuelfwerr/london-weather-data')
guillemservera_global_daily_climate_data_path = kagglehub.dataset_download('guillemservera/global-daily-climate-data')
valentindefour_badminton_world_rankings_updated_august_2020_path = kagglehub.dataset_download('valentindefour/badminton-world-rankings-updated-august-2020')
thedevastator_weather_prediction_path = kagglehub.dataset_download('thedevastator/weather-prediction')
aditya0kumar0tiwari_play_badminton_path = kagglehub.dataset_download('aditya0kumar0tiwari/play-badminton')
jatinthakur706_top_100_badminton_players_path = kagglehub.dataset_download('jatinthakur706/top-100-badminton-players')

print('Data source import complete.')

# The rest of the script (HTML, Markdown) is treated as comments in a .py file.
# We are keeping it for completeness as requested.

import pandas as pd
import numpy as np

import matplotlib.pyplot as plt # for visualization
import seaborn as sns # for Visualization

from itertools import combinations # For visualization columns combination.

# For Chi Square test
from scipy.stats import chi2_contingency

# For spliting the dataset into Training and testing.
from sklearn.model_selection import train_test_split

# Naive Bayes ALgorithm
from sklearn.naive_bayes import BernoulliNB

# For Model Evaluation
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

from warnings import filterwarnings
filterwarnings('ignore')

# CORRECTION 2: Use the path from kagglehub to load the CSV file
# The variable 'aditya0kumar0tiwari_play_badminton_path' contains the folder path.
# We join it with the filename 'badminton_dataset.csv' to get the full path.
full_file_path = os.path.join(aditya0kumar0tiwari_play_badminton_path, 'badminton_dataset.csv')
df = pd.read_csv(full_file_path)

# --- Start of Analysis ---

print("\n--- Displaying first 7 rows ---")
print(df.head(7))

print("\n--- Columns in Dataset ---")
print(df.columns)

print("\n--- Data Types ---")
print(df.dtypes)

print("\n--- Summary Statistics ---")
num_rows, num_columns = df.shape
print(f'Number of rows: {num_rows}')
print(f'Number of columns: {num_columns}')
summary = df.describe(include='object')
print(summary)

print("\n--- Distribution of Categorical Variables ---")
for column in df.select_dtypes(include=['object']).columns:
    print(f'\\nValue counts for {column}:')
    print(df[column].value_counts())

print("\n--- Checking for Missing Values ---")
print(df.isnull().sum())

print("\n--- Dataset Info (for outlier check context) ---")
df.info()

def plot_categorical_distribution(df, columns, colors=None, background_color=None, foreground_color=None):
    if background_color:
        plt.rcParams['figure.facecolor'] = background_color
    if foreground_color:
        plt.rcParams['axes.labelcolor'] = foreground_color
        plt.rcParams['axes.edgecolor'] = foreground_color
        plt.rcParams['xtick.color'] = foreground_color
        plt.rcParams['ytick.color'] = foreground_color

    for col in columns:
        if col in df.columns:
            color = colors[col] if colors and col in colors else None
            
            plt.figure() # Create a new figure for each plot
            df[col].value_counts().plot(kind='bar', color=color)
            plt.title(f'Distribution of {col}')
            plt.xlabel(col)
            plt.ylabel('Frequency')
            plt.show()
        else:
            print(f"Column '{col}' not found in the DataFrame.")

custom_colors = {
    'Outlook': 'lightblue',
    'Temperature': 'lightgreen',
    'Humidity': 'lightsalmon',
    'Wind': 'lightcoral',
    'Play_Badminton': 'lightgray'
}

print("\n--- Visualizing Distributions ---")
plot_categorical_distribution(df, ['Outlook'], colors=custom_colors, background_color='#FFEFD5', foreground_color='black')
plot_categorical_distribution(df, ['Temperature'], colors=custom_colors, background_color='#FFEFD5', foreground_color='black')
plot_categorical_distribution(df, ['Humidity'], colors=custom_colors, background_color='#FFEFD5', foreground_color='black')
plot_categorical_distribution(df, ['Wind'], colors=custom_colors, background_color='#FFEFD5', foreground_color='black')
plot_categorical_distribution(df, ['Play_Badminton'], colors=custom_colors, background_color='#FFEFD5', foreground_color='black')

print("\n--- Chi-Square Tests ---")
for column in df.columns[:-1]:
    contingency_table = pd.crosstab(df['Play_Badminton'], df[column])
    chi2, p, _, _ = chi2_contingency(contingency_table)
    print(f"Chi-square test for independence between {column} and 'Play_Badminton':")
    print(f"Chi2 value: {chi2}, p-value: {p}")
    if p < 0.05:
        print(f"The variable {column} is likely not independent of 'Play_Badminton'.")
    else:
        print(f"The variable {column} is likely independent of 'Play_Badminton'.")
    print()

def plot_categorical_relationships(df, columns):
    for col1, col2 in combinations(columns, 2):
        if col1 in df.columns and col2 in df.columns:
            plt.figure(figsize=(6, 4))
            crosstab = pd.crosstab(df[col1], df[col2], normalize='index') * 100
            sns.heatmap(crosstab, annot=True, cmap='coolwarm', fmt='.2f')
            plt.title(f'Heatmap of {col1} vs {col2}')
            plt.xlabel(col2)
            plt.ylabel(col1)
            plt.show()
        else:
            print(f"One of the columns '{col1}' or '{col2}' not found in the DataFrame.")

print("\n--- Visualizing Relationships with Play_Badminton ---")
plot_categorical_relationships(df, ['Outlook', 'Play_Badminton'])
plot_categorical_relationships(df, ['Temperature', 'Play_Badminton'])
plot_categorical_relationships(df, ['Humidity', 'Play_Badminton'])
plot_categorical_relationships(df, ['Wind', 'Play_Badminton'])

print("\n--- Model Preparation ---")
print("Original shape:", df.shape)
df_encoded = pd.get_dummies(df)
print("Encoded shape:", df_encoded.shape)

X = df_encoded.iloc[:, :-1]
y = df_encoded.iloc[:, -1]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("\n--- Model Training ---")
bnb_classifier = BernoulliNB()
bnb_classifier.fit(X_train, y_train)
y_pred = bnb_classifier.predict(X_test)

print("\n--- Model Evaluation ---")
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)
precision = precision_score(y_test, y_pred)
print("Precision:", precision)
recall = recall_score(y_test, y_pred)
print("Recall:", recall)
f1 = f1_score(y_test, y_pred)
print("F1 Score:", f1)
conf_matrix = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(conf_matrix)

plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix, annot=True, cmap="Blues", fmt="d",
            xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()
